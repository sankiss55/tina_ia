<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>YOLO Detector en Vivo</title>

  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0"></script>

  <style>
    body {
      margin: 0;
      background: #1a1a1a;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
      font-family: sans-serif;
      color: white;
    }
    #wrapper {
      position: relative;
      border: 4px solid #333;
      border-radius: 12px;
      overflow: hidden;
      box-shadow: 0 10px 30px rgba(0,0,0,0.5);
    }
    video, canvas {
      display: block;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    #status {
      margin-bottom: 15px;
      padding: 8px 16px;
      border-radius: 20px;
      background: #333;
      font-weight: bold;
    }
  </style>
</head>

<body>

  <div id="status">INICIALIZANDO...</div>

  <div id="wrapper">
    <video id="video" width="640" height="480" autoplay playsinline muted></video>
    <canvas id="canvas"></canvas>
  </div>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const status = document.getElementById("status");

    let model;
    const CONF_THRESHOLD = 0.5;

    // üî• CONTROL DE RENDIMIENTO
    let frameCount = 0;
    const DETECT_EVERY_N_FRAMES = 8; // ‚Üê cambia a 10 si sigue lento

    // 1Ô∏è‚É£ FORZAR GPU (WEBGL)
    async function forceBackend() {
      await tf.setBackend('webgl');
      await tf.ready();

      const backend = tf.getBackend();

      if (backend === 'webgl') {
        alert('‚úÖ TensorFlow.js est√° usando GPU (WebGL)');
        status.textContent = 'GPU ACTIVADA (WEBGL)';
        status.style.background = '#006600';
      } else {
        alert('‚ùå TensorFlow.js est√° usando CPU');
        status.textContent = 'CPU (LENTO)';
        status.style.background = '#660000';
      }

      console.log('Backend:', backend);
    }

    // 2Ô∏è‚É£ C√ÅMARA
    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 640, height: 480, facingMode: "environment" }
      });
      video.srcObject = stream;
      return new Promise(resolve => video.onloadedmetadata = resolve);
    }

    // 3Ô∏è‚É£ MODELO
    async function loadYOLO() {
      status.textContent = "CARGANDO MODELO...";
      model = await tf.loadGraphModel("./model/model.json");
      status.textContent = "MODELO LISTO - BUSCANDO...";
      status.style.background = "#333";
    }

    // 4Ô∏è‚É£ LOOP PRINCIPAL
    async function detectLoop() {
      frameCount++;

      // Dibujar video siempre (fluidez)
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      // üî• SOLO DETECTAR CADA X FRAMES
      if (frameCount % DETECT_EVERY_N_FRAMES === 0) {
        await detectFrame();
      }

      requestAnimationFrame(detectLoop);
    }

    // 5Ô∏è‚É£ DETECCI√ìN
    async function detectFrame() {
      if (!model) return;

      const input = tf.tidy(() => {
        return tf.browser.fromPixels(video)
          .resizeBilinear([640, 640])
          .div(255.0)
          .expandDims(0);
      });

      let output = model.execute(input);

      let raw;
      if (output instanceof tf.Tensor) raw = output;
      else if (Array.isArray(output)) raw = output[0];
      else raw = output[Object.keys(output)[0]];

      if (raw.shape[1] < raw.shape[2]) {
        raw = raw.transpose([0, 2, 1]);
      }

      const data = await raw.array();
      const predictions = data[0];

      let found = false;

      predictions.forEach(row => {
        const scores = row.slice(4);
        const maxScore = Math.max(...scores);

        if (maxScore > CONF_THRESHOLD) {
          found = true;

          const [cx, cy, w, h] = row.slice(0, 4);

          const scaleX = canvas.width / 640;
          const scaleY = canvas.height / 640;

          const width = w * scaleX;
          const height = h * scaleY;
          const x = (cx * scaleX) - width / 2;
          const y = (cy * scaleY) - height / 2;

          ctx.strokeStyle = "#00FF00";
          ctx.lineWidth = 3;
          ctx.strokeRect(x, y, width, height);

          ctx.fillStyle = "#00FF00";
          ctx.font = "16px Arial";
          const label = `${(maxScore * 100).toFixed(0)}%`;
          ctx.fillRect(x, y - 22, ctx.measureText(label).width + 10, 22);
          ctx.fillStyle = "#000";
          ctx.fillText(label, x + 5, y - 6);
        }
      });

      status.textContent = found
        ? "OBJETO DETECTADO CON IA"
        : "BUSCANDO OBJETOS...";

      tf.dispose([input, output, raw]);
    }

    // 6Ô∏è‚É£ START
    async function main() {
      try {
        await forceBackend();
        await setupCamera();
        await loadYOLO();
        detectLoop();
      } catch (e) {
        console.error(e);
        status.textContent = "ERROR AL INICIAR";
      }
    }

    main();
  </script>

</body>
</html>
          
